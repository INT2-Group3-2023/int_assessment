# -*- coding: utf-8 -*-
"""a new start.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Eqxiif_mCQHZZYBZX2z-0KIvZ1VMb71
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras import layers
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

data, ds_info = tfds.load('oxford_flowers102', 
                         with_info=True, 
                          as_supervised=True,
                          shuffle_files = True)
train_ds, valid_ds, test_ds = data['train'], data['validation'], data['test']

type(train_ds)

print(type(train_ds))

#transform images to the chosen dimension (they are just squeezed)
def scale_resize_image(image, label):
    image = tf.image.convert_image_dtype(image, tf.float32) # equivalent to dividing image pixels by 255
    image = tf.image.resize(image, (128, 128)) # Resizing the image to 224x224 dimention
    return (image, label)

def rgb_convert(image, label):
    image = tf.image.rgb_to_grayscale(image)
    return (image, label)

def crop_image(image, label):
    image = tf.image.resize_with_crop_or_pad(image, 500, 500)
    return (image, label)

AUTO = tf.data.experimental.AUTOTUNE
BATCH_SIZE = 256

training_ds = (train_ds.map(crop_image))
training_ds = (training_ds.map(scale_resize_image))
#training_ds = (training_ds.map(rgb_convert))
training_ds = training_ds.batch(BATCH_SIZE)

testing_ds = (test_ds.map(crop_image))
testing_ds = (testing_ds.map(scale_resize_image))
#testing_ds = testing_ds.map(rgb_convert)
testing_ds = testing_ds.batch(BATCH_SIZE)

counter = 0
for example in train_ds:
  counter = counter + 1
print(counter)

#for example in training_ds:
#  print(example[0].shape)

#display the resized images
#fig = tfds.show_examples(training_ds, ds_info, rows = 4, cols = 4)

model = keras.Sequential([
    keras.Input((128, 128, 3)),
    keras.layers.Conv2D(16, 3, activation='relu'),
    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),

#this layer didnt make much difference
#    keras.layers.Conv2D(16, 3, activation='relu'),
#    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),
#    keras.layers.Dropout(0.5),
    
    keras.layers.Flatten(),
    keras.layers.Dense(102, activation=tf.nn.softmax)
])

model.summary()

model.compile(
    optimizer = keras.optimizers.Adam(learning_rate = 0.001),
    loss = keras.losses.SparseCategoricalCrossentropy(),
    metrics = ["accuracy"]
)

model.fit(training_ds, epochs = 100, verbose=2)
model.evaluate(testing_ds)